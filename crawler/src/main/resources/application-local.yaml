server:
  port: 5960
spring:
  data:
    mongodb:
      host: localhost
      port: 27017
      database: crawler-db
  kafka:
    consumer:
      auto-offset-reset: latest
kafka:
  url: localhost:9092
  requestTopic: crawler.request
  responseTopic: crawler.response
  pageTopic: crawler.pages
  groupId: crawler.group
  maxMessageSize: 10485760
logging:
  level:
    com.osearch.crawler: INFO
    org.apache.kafka: ERROR
    org.apache.kafka.clients.consumer.ConsumerConfig: OFF
management:
  endpoint:
    health:
      probes:
        enabled: true
service:
  crawlerThreadsCount: 6
  processorThreadsCount: 6
  pagesToKeep: 20000
  externalUrlRegex: "((http|https)://[\\w\\d:#@%/;$()~_?\\+-=\\\\\\.&]*)"
  invalidUrlRegex: ".*\\.(js|txt|json|csv|pdf|xml|mp3|mp4|avi|mov|zip|rar|exe|jpg|jpeg|gif|png|svg)$"
rest:
  timeout: 10000
  maxRedirects: 5
  userAgent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36
swagger:
  url: /swagger-ui/index.html
  title: Crawler API [LOCAL PROFILE]
  description: This API allows you to work with crawler service
  version: "1.5"
  controllersPackage: com.osearch.crawler.adapter.in.rest
